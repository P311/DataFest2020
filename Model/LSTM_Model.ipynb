{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import LSTM\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_Model(data, wv_from_bin, batch_size=128, kernel_size=5, max_length=1000, vec_size=200):\n",
    "    \n",
    "    # Preparing Text Data and Label\n",
    "    tweet, label = data['text'], data['sentiment']\n",
    "    \n",
    "    # Tokenizing Text\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(tweet)\n",
    "    sequences = tokenizer.texts_to_sequences(tweet)\n",
    "\n",
    "    # Preparing Embedding Dictionary\n",
    "    word_index = tokenizer.word_index\n",
    "    tweets_pad = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "    embedding_index = {}\n",
    "    words = list(wv_from_bin.vocab.keys())\n",
    "    curInd = 0\n",
    "    for w in words:\n",
    "        try:\n",
    "            embedding_index[w] = wv_from_bin.word_vec(w)\n",
    "            curInd += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "            \n",
    "    # Preparing Embedding Matrix\n",
    "    embedding_matrix = np.zeros((len(tokenizer.word_index) + 1, vec_size))\n",
    "    words = []\n",
    "    for word, i in word_index.items():\n",
    "        words.append(word)\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    # Preparing Embedding Layer\n",
    "    embedding_layer = Embedding(len(tokenizer.word_index) + 1,\n",
    "                            vec_size,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)\n",
    "    \n",
    "    # Construction CNN Model Structure\n",
    "    model = Sequential()\n",
    "    model.add(embedding_layer)\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dense(64))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n",
    "    filepath = \"/Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-{epoch:02d}-{loss:0.3f}-{mean_squared_error:0.3f}-{val_loss:0.3f}-{val_mean_squared_error:0.3f}.hdf5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor=\"loss\", verbose=1, save_best_only=True, mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=0.000001)\n",
    "    print(model.summary())\n",
    "\n",
    "    # Training Model\n",
    "    model.fit(tweets_pad, label, batch_size=batch_size, epochs=8, validation_split=0.1, shuffle=True, callbacks=[checkpoint, reduce_lr])\n",
    "    \n",
    "    # Saving Trained Model\n",
    "    model.save(\"/Users/colinwan/Desktop/DataFest2020/Models/LSTM.h5\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colinwan/Desktop/DataFest2020/Models/utils.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][i] = \" \".join([word for word in df['text'][i].split()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 200)         2492800   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 200)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,669,569\n",
      "Trainable params: 176,769\n",
      "Non-trainable params: 2,492,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12483 samples, validate on 1388 samples\n",
      "Epoch 1/8\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    wv_from_bin = utils.load_embedding_model(200)\n",
    "    data = pd.read_csv('/Users/colinwan/Desktop/DataFest2020/Training Folder/Sentiment.csv')\n",
    "    data = data[['text','sentiment']]\n",
    "    data = data.replace('Neutral', 0)\n",
    "    data = data.replace('Positive', 1)\n",
    "    data = data.replace('Negative', -1)\n",
    "    data = utils.clean_text(data)\n",
    "    data['text'] = data['text'].str.replace('[^A-Za-z ]+', '')\n",
    "    LSTM_Model(data, wv_from_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded vocab size 400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/colinwan/Desktop/DataFest2020/Models/utils.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'][i] = \" \".join([word for word in df['text'][i].split()\n"
     ]
    }
   ],
   "source": [
    "wv_from_bin = utils.load_embedding_model(200)\n",
    "data = pd.read_csv('/Users/colinwan/Desktop/DataFest2020/Training Folder/Sentiment.csv')\n",
    "data = data[['text','sentiment']]\n",
    "data = data.replace('Neutral', 0)\n",
    "data = data.replace('Positive', 1)\n",
    "data = data.replace('Negative', -1)\n",
    "data = utils.clean_text(data)\n",
    "data['text'] = data['text'].str.replace('[^A-Za-z ]+', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1000, 200)         2492800   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 200)         0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               168448    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 2,669,569\n",
      "Trainable params: 176,769\n",
      "Non-trainable params: 2,492,800\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /Users/colinwan/opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 12483 samples, validate on 1388 samples\n",
      "Epoch 1/8\n",
      "12483/12483 [==============================] - 878s 70ms/step - loss: 0.7308 - mean_squared_error: 0.7308 - val_loss: 0.7318 - val_mean_squared_error: 0.7318\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.73076, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-01-0.731-0.731-0.732-0.732.hdf5\n",
      "Epoch 2/8\n",
      "12483/12483 [==============================] - 706s 57ms/step - loss: 0.6685 - mean_squared_error: 0.6685 - val_loss: 0.6741 - val_mean_squared_error: 0.6741\n",
      "\n",
      "Epoch 00002: loss improved from 0.73076 to 0.66854, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-02-0.669-0.669-0.674-0.674.hdf5\n",
      "Epoch 3/8\n",
      "12483/12483 [==============================] - 822s 66ms/step - loss: 0.6281 - mean_squared_error: 0.6281 - val_loss: 0.6364 - val_mean_squared_error: 0.6364\n",
      "\n",
      "Epoch 00003: loss improved from 0.66854 to 0.62814, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-03-0.628-0.628-0.636-0.636.hdf5\n",
      "Epoch 4/8\n",
      "12483/12483 [==============================] - 867s 69ms/step - loss: 0.6032 - mean_squared_error: 0.6032 - val_loss: 0.6126 - val_mean_squared_error: 0.6126\n",
      "\n",
      "Epoch 00004: loss improved from 0.62814 to 0.60320, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-04-0.603-0.603-0.613-0.613.hdf5\n",
      "Epoch 5/8\n",
      "12483/12483 [==============================] - 787s 63ms/step - loss: 0.5883 - mean_squared_error: 0.5883 - val_loss: 0.5976 - val_mean_squared_error: 0.5976\n",
      "\n",
      "Epoch 00005: loss improved from 0.60320 to 0.58831, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-05-0.588-0.588-0.598-0.598.hdf5\n",
      "Epoch 6/8\n",
      "12483/12483 [==============================] - 731s 59ms/step - loss: 0.5797 - mean_squared_error: 0.5797 - val_loss: 0.5884 - val_mean_squared_error: 0.5884\n",
      "\n",
      "Epoch 00006: loss improved from 0.58831 to 0.57974, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-06-0.580-0.580-0.588-0.588.hdf5\n",
      "Epoch 7/8\n",
      "12483/12483 [==============================] - 847s 68ms/step - loss: 0.5749 - mean_squared_error: 0.5749 - val_loss: 0.5826 - val_mean_squared_error: 0.5826\n",
      "\n",
      "Epoch 00007: loss improved from 0.57974 to 0.57493, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-07-0.575-0.575-0.583-0.583.hdf5\n",
      "Epoch 8/8\n",
      "12483/12483 [==============================] - 915s 73ms/step - loss: 0.5723 - mean_squared_error: 0.5723 - val_loss: 0.5793 - val_mean_squared_error: 0.5793\n",
      "\n",
      "Epoch 00008: loss improved from 0.57493 to 0.57233, saving model to /Users/colinwan/Desktop/DataFest2020/checkpoint/LSTM/lstm-08-0.572-0.572-0.579-0.579.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x1a5ae03e10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM_Model(data, wv_from_bin, batch_size=128, kernel_size=5, max_length=1000, vec_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
